{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Импорт библиотек"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd; pd.set_option('display.max_columns', None)\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, GridSearchCV\n",
    "\n",
    "# Инструкция по установке пакета: https://github.com/maks-sh/scikit-uplift\n",
    "# Инстркция на документацию: https://scikit-uplift.readthedocs.io/en/latest/\n",
    "from sklift.metrics import uplift_at_k\n",
    "from sklift.viz import plot_uplift_preds\n",
    "from sklift.models import SoloModel\n",
    "from sklift.models import ClassTransformation\n",
    "\n",
    "# sklift поддерживает любые модели, \n",
    "# которые удовлетворяют соглашениями scikit-learn\n",
    "# Для примера воспользуемся catboost\n",
    "from catboost import CatBoostClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV\n",
    "\n",
    "from sklift.preprocess import balancer\n",
    "from datetime import datetime\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Получение выборки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_TO_DATA = 'C:/Users/Anatoly/1python/X5retail/heroX5-master/data/'\n",
    "# Чтение данных\n",
    "# Выбросим последнего пользователя\n",
    "df_clients = pd.read_csv(PATH_TO_DATA+ 'clients.csv', index_col='client_id').iloc[:-1,:]\n",
    "df_train = pd.read_csv(PATH_TO_DATA+ 'uplift_train.csv', index_col='client_id').iloc[:-1,:]\n",
    "df_test = pd.read_csv(PATH_TO_DATA+ 'uplift_test.csv', index_col='client_id')\n",
    "\n",
    "# Извлечение признаков\n",
    "df_features = df_clients.copy()\n",
    "\n",
    "cat_features =['gender']\n",
    "    \n",
    "models_results = {\n",
    "    'approach': [],\n",
    "    'uplift@30%': []\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delay_time(data):\n",
    "    '''\n",
    "    Calculate delay in seconds/10*6 beetween datetime dataseries.\n",
    "    Return finish dataset.\n",
    "    \n",
    "    Args:\n",
    "        data(Dataframe): data with columns 'first_issue_date', 'first_redeem_date'\n",
    "        \n",
    "    '''\n",
    "    \n",
    "    issue_date = data['first_issue_date'] \n",
    "    redeem_date = data['first_redeem_date'] \n",
    "    \n",
    "    redeem_time = pd.to_datetime(redeem_date)\n",
    "    issue_time = pd.to_datetime(issue_date)\n",
    "    \n",
    "    start_time = datetime(2000,1,1)\n",
    "    delay = []\n",
    "    issue_sec = []\n",
    "    redeem_sec = []\n",
    "    for redeem,issue in zip(redeem_time, issue_time):\n",
    "        # if x not None\n",
    "        issue_sec.append((issue - start_time).seconds)\n",
    "        \n",
    "        if redeem==redeem:\n",
    "            redeem_sec.append((redeem - start_time).seconds)\n",
    "            delay.append((redeem - issue).seconds/10**4)\n",
    "        else:\n",
    "            delay.append(0)\n",
    "            redeem_sec.append(0)\n",
    "            \n",
    "    \n",
    "    data['issue_redeem_delay'] = np.array(delay)\n",
    "    data['first_issue_time'] = np.array(issue_sec)\n",
    "    data['first_redeem_time'] = np.array(redeem_sec) \n",
    "    \n",
    "    data = data.drop(['first_issue_date', 'first_redeem_date'], axis=1)\n",
    "    \n",
    "    return data\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 16.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df_features = delay_time(df_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Соединяем с моими признаками\n",
    "df_my = pd.read_csv(PATH_TO_DATA + 'all_users.csv',index_col='client_id')\n",
    "df_features = df_features.join(df_my)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_train_test(df_train, df_test, data, estimator=None):\n",
    "    '''\n",
    "    Split data to train and validation.\n",
    "    Return X_train, y_train, treat_train; X_val, y_val, treat_val; X_train_full, y_train_full, treat_train_full, data\n",
    "    \n",
    "    Args: \n",
    "        df_train: train data with treatment and target\n",
    "        df_test: trest data with treatment and target\n",
    "        data_feats: data with features\n",
    "        estimator(str): estimator that will train\n",
    "    '''\n",
    "\n",
    "    data_feats = data.copy()\n",
    "    cat_features = ['gender']\n",
    "    # One-hot encoding for estimators which are not catboost\n",
    "    if estimator!='catboost':\n",
    "        data_feats['F'] = (data_feats.gender=='F').astype(int)\n",
    "        data_feats['M'] = (data_feats.gender=='M').astype(int)\n",
    "        data_feats['U'] = (data_feats.gender=='U').astype(int)\n",
    "        cat_features = ['F','M','U']\n",
    "        data_feats = data_feats.drop(columns='gender')\n",
    "    \n",
    "    # Присваеваем индексы трейн и тест, обучения и валидации\n",
    "    indices_train = df_train.index\n",
    "    indices_test = df_test.index\n",
    "    indices_learn, indices_valid = train_test_split(df_train.index, test_size=0.3, random_state=123) #, stratify=df_train.treatment_flg)\n",
    "\n",
    "\n",
    "    # Обучающая выборка\n",
    "    X_train = data_feats.loc[indices_learn, :]\n",
    "    y_train = df_train.loc[indices_learn, 'target']\n",
    "    treat_train = df_train.loc[indices_learn, 'treatment_flg']\n",
    "\n",
    "    # Валидационная выборка\n",
    "    X_val = data_feats.loc[indices_valid, :]\n",
    "    y_val = df_train.loc[indices_valid, 'target']\n",
    "    treat_val =  df_train.loc[indices_valid, 'treatment_flg']\n",
    "\n",
    "    # Полные данные\n",
    "    X_train_full = data_feats.loc[indices_train, :]\n",
    "    y_train_full = df_train.loc[:, 'target']\n",
    "    treat_train_full = df_train.loc[:, 'treatment_flg']\n",
    "\n",
    "    X_test = data_feats.loc[indices_test, :]\n",
    "    \n",
    "    return X_train, y_train, treat_train,\\\n",
    "           X_val, y_val, treat_val,\\\n",
    "           X_train_full, y_train_full, treat_train_full,\\\n",
    "           cat_features, data_feats, X_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Standartization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'StandardScaler' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-4af8b2bcc2e2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mscaled_data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m \u001b[0mscaled_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscale_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_features\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-8-4af8b2bcc2e2>\u001b[0m in \u001b[0;36mscale_data\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mscale_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0mscaler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mStandardScaler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m     \u001b[0mscaler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'StandardScaler' is not defined"
     ]
    }
   ],
   "source": [
    "# Не помогло\n",
    "def scale_data(data):\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(data.iloc[:,2:])\n",
    "    \n",
    "    scaled_data = pd.DataFrame(scaler.transform(data.iloc[:,2:]), columns=data.iloc[:,2:].columns, index=data.index)\n",
    "    scaled_data = pd.concat([data.iloc[:,:2],scaled_data], axis=1)\n",
    "    \n",
    "    return scaled_data\n",
    "\n",
    "scaled_data = scale_data(df_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Auto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_table(estimator, model, score, balance, models_results):\n",
    "    estimator_name = str(estimator).replace(\"'\",\"\").replace('<','').replace('>','').split('.')[-1]\n",
    "    approach_name = str(model).replace(\"'\",\"\").replace('<','').replace('>','').split('.')[-1]\n",
    "\n",
    "    models_results['approach'].append(approach_name)\n",
    "    models_results['balance'].append(balance)\n",
    "    models_results['estimator'].append(estimator_name)\n",
    "    models_results['uplift@30%'].append(score)\n",
    "    \n",
    "    return models_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def choose_model(estimators, models, data_feat, df_train, df_test):\n",
    "    '''\n",
    "    Create table with results of training model.\n",
    "    \n",
    "    Args:\n",
    "        estimator:  classifier\n",
    "        model: model of uplift (SoloModel, ClassTransformation)\n",
    "        data_feat : training and validation data with features\n",
    "        df_train : train data with target and treatment\n",
    "        df_test : test data with target and treatment\n",
    "    '''\n",
    "    \n",
    "        \n",
    "    models_results = {\n",
    "    'approach': [],\n",
    "    'balance': [],\n",
    "    'estimator': [],\n",
    "    'uplift@30%': []\n",
    "    }\n",
    "    \n",
    "    \n",
    "    df_features = data_feat.copy()\n",
    "    \n",
    "    for estimator in estimators:\n",
    "        for model in models:\n",
    "            for i, balance in enumerate(['balanced','not balanced']):\n",
    "                # Initialization \n",
    "                if estimator==CatBoostClassifier:\n",
    "                    X_train, y_train, treat_train,\\\n",
    "                    X_val, y_val, treat_val,\\\n",
    "                    X_train_full, y_train_full, treat_train_full,\\\n",
    "                    cat_features, df_features_est, X_test = initialize_train_test(df_train, df_test, df_features, 'catboost')\n",
    "\n",
    "                    if balance=='balanced':\n",
    "                        X_train, treat_train, y_train = balancer(X_train, treat_train, y_train, random_state=0, verbose=False)\n",
    "                        X_train = pd.DataFrame(X_train, columns = df_features_est.columns)\n",
    "\n",
    "                if estimator!=CatBoostClassifier:\n",
    "                    X_train, y_train, treat_train,\\\n",
    "                    X_val, y_val, treat_val,\\\n",
    "                    X_train_full, y_train_full, treat_train_full,\\\n",
    "                    cat_features, df_features_est, X_test = initialize_train_test(df_train, df_test, df_features)\n",
    "\n",
    "                    if balance=='balanced':\n",
    "                        X_train, treat_train, y_train = balancer(X_train, treat_train, y_train, random_state=0, verbose=False)\n",
    "                        X_train = pd.DataFrame(X_train, columns = df_features_est.columns)\n",
    "\n",
    "                # Estimation\n",
    "                if estimator==CatBoostClassifier:\n",
    "                    uplift_model = model(estimator(thread_count=2, random_state=42, silent=True))\n",
    "                    uplift_model = uplift_model.fit(X_train, y_train, treat_train, estimator_fit_params={'cat_features': cat_features})\n",
    "\n",
    "                if estimator!=CatBoostClassifier:\n",
    "                    uplift_model = model(estimator(random_state=42))\n",
    "                    uplift_model = uplift_model.fit(X_train, y_train, treat_train)\n",
    "\n",
    "                uplift_model_predict = uplift_model.predict(X_val)\n",
    "                uplift_score = uplift_at_k(y_true=y_val, uplift=uplift_model_predict, treatment=treat_val, k=0.3)\n",
    "                models_results = update_table(estimator, model, uplift_score, balance, models_results)\n",
    "    \n",
    "    return pd.DataFrame(data=models_results).sort_values('uplift@30%', ascending=False)\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimators = [CatBoostClassifier, XGBClassifier, RandomForestClassifier, DecisionTreeClassifier]\n",
    "models = [SoloModel, ClassTransformation]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anatoly\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:51: UserWarning: It is recommended to use this approach on treatment balanced data. Current sample size is unbalanced.\n",
      "C:\\Users\\Anatoly\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:55: UserWarning: It is recommended to use this approach on treatment balanced data. Current sample size is unbalanced.\n",
      "C:\\Users\\Anatoly\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Users\\Anatoly\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Users\\Anatoly\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Users\\Anatoly\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:55: UserWarning: It is recommended to use this approach on treatment balanced data. Current sample size is unbalanced.\n",
      "C:\\Users\\Anatoly\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Users\\Anatoly\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:55: UserWarning: It is recommended to use this approach on treatment balanced data. Current sample size is unbalanced.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 10min 24s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "models_results = choose_model(estimators, models, df_features, df_train, df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>approach</th>\n",
       "      <th>balance</th>\n",
       "      <th>estimator</th>\n",
       "      <th>uplift@30%</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>SoloModel</td>\n",
       "      <td>not balanced</td>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>0.063509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>SoloModel</td>\n",
       "      <td>balanced</td>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>0.061864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>SoloModel</td>\n",
       "      <td>balanced</td>\n",
       "      <td>CatBoostClassifier</td>\n",
       "      <td>0.060889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>SoloModel</td>\n",
       "      <td>not balanced</td>\n",
       "      <td>CatBoostClassifier</td>\n",
       "      <td>0.054664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>ClassTransformation</td>\n",
       "      <td>balanced</td>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>0.053876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>ClassTransformation</td>\n",
       "      <td>not balanced</td>\n",
       "      <td>CatBoostClassifier</td>\n",
       "      <td>0.050547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>ClassTransformation</td>\n",
       "      <td>not balanced</td>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>0.047768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>ClassTransformation</td>\n",
       "      <td>balanced</td>\n",
       "      <td>CatBoostClassifier</td>\n",
       "      <td>0.047319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>ClassTransformation</td>\n",
       "      <td>not balanced</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>0.043689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>SoloModel</td>\n",
       "      <td>balanced</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>0.041901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>SoloModel</td>\n",
       "      <td>not balanced</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>0.038678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>ClassTransformation</td>\n",
       "      <td>balanced</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>0.038140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>ClassTransformation</td>\n",
       "      <td>balanced</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>0.035246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>SoloModel</td>\n",
       "      <td>balanced</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>0.033965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>ClassTransformation</td>\n",
       "      <td>not balanced</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>0.032691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>SoloModel</td>\n",
       "      <td>not balanced</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>0.031975</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               approach       balance               estimator  uplift@30%\n",
       "5             SoloModel  not balanced           XGBClassifier    0.063509\n",
       "4             SoloModel      balanced           XGBClassifier    0.061864\n",
       "0             SoloModel      balanced      CatBoostClassifier    0.060889\n",
       "1             SoloModel  not balanced      CatBoostClassifier    0.054664\n",
       "6   ClassTransformation      balanced           XGBClassifier    0.053876\n",
       "3   ClassTransformation  not balanced      CatBoostClassifier    0.050547\n",
       "7   ClassTransformation  not balanced           XGBClassifier    0.047768\n",
       "2   ClassTransformation      balanced      CatBoostClassifier    0.047319\n",
       "15  ClassTransformation  not balanced  DecisionTreeClassifier    0.043689\n",
       "12            SoloModel      balanced  DecisionTreeClassifier    0.041901\n",
       "13            SoloModel  not balanced  DecisionTreeClassifier    0.038678\n",
       "10  ClassTransformation      balanced  RandomForestClassifier    0.038140\n",
       "14  ClassTransformation      balanced  DecisionTreeClassifier    0.035246\n",
       "8             SoloModel      balanced  RandomForestClassifier    0.033965\n",
       "11  ClassTransformation  not balanced  RandomForestClassifier    0.032691\n",
       "9             SoloModel  not balanced  RandomForestClassifier    0.031975"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models_results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
